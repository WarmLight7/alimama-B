## 数据范围：

广告数据大小说明：

总文件大小 69G

关键词的数量keywrod(uint64)： ～100万

广告单元的数量adgroup_id(uint64)  ： ～500万

广告计划的数据campaign_id：～100万

广告单元上的关键词数量keywrod(uint64)： ～100

## 服务资源：

服务可运行在最多**3个16G内存16cpu的容器**中

## 数据存储格式：

| keywrod(uint64) | adgroup_id(uint64) | price(uint64) | status(int8) |
| --------------- | ------------------ | ------------- | ------------ |
| 2916200016      | 644960096148       | 63885         | 1            |

| timings(int8, 0/1列表，长度24)                  | vector(float列表) | campaign_id(uint64) | item_id(uint64) |
| ----------------------------------------------- | ----------------- | ------------------- | --------------- |
| 0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,1,0,1,1,0,1,0,0 | 0.993916,1        | 217245901050        | 646829064714    |

## 请求值：

| keywrod(uint64) | vector(float列表) | hour | topn |
| --------------- | ----------------- | ---- | ---- |
| 2916200016      | 0.351177,0.936309 | 7    | 2    |



## 返回值：

topn个response：

| adgroup_id(uint64)         | prices      |
| -------------------------- | ----------- |
| 644960096148,1710671559561 | 27435,39778 |



## 任务理解：

核心是**广告单元** 我们返回的是广告单元的id

如果一开始的理解没有错误的话 ，一开始的时间是固定的，并且每过一段时间hour字段才会变

- 第一步要处理的就是按照时间对data进行切片

  - 涉及到csv的分块读写

  - 把/data/raw_data.csv中的文件按照时间切片切成/data/time1-24.csv

  - 存储格式为：

  - | keywrod(uint64) | adgroup_id(uint64) | price(uint64) | vector(float列表) |
    | --------------- | ------------------ | ------------- | ----------------- |
    | 2916200016      | 644960096148       | 63885         | 0.993916,1        |

  - 注：这里item_id也不知道他存在的意义是啥，他和推广单元是1对1的

- 处理为预先加载当前的时间节点请求（问题是怎么知道一开始所需求的时间节点是多少呢）

  - 经过上述处理体感单个时间节点的数据量级直接缩小一个数量级即7G左右(存疑惑，这样单机不就跑通了吗)
  - 那么单机可以容纳两个时间点的需求数量
  - 处理方法跟初赛的版本切换方法类似 绑定k个核心用来做版本切换（调参行为,一开始可以直接设置一半吧）







